import pandas as pd
import numpy as np
from ast import literal_eval

df1=pd.read_csv('dataset/tmdb_5000_credits.csv')
df2=pd.read_csv('dataset/tmdb_5000_movies.csv')



df1.columns = ['id', 'title', 'cast', 'crew']
df2 = df2.merge(df1, on='id')


"""# **Content Based FIltering**"""

df2['overview'].head(3)

"""**Using TF-IDF**"""

from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer(stop_words='english')

df2['overview'] = df2['overview'].fillna('')
tfidf_matrix = tfidf.fit_transform(df2['overview'])
tfidf_matrix.shape


from sklearn.metrics.pairwise import linear_kernel
cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)

indices = pd.Series(df2.index, index=df2['original_title']).drop_duplicates()

def get_recommendations(title, cosine_sim=cosine_sim):
    idx = indices[title]

    sim_scores = list(enumerate(cosine_sim[idx]))

    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:11]
    movie_indices = [i[0] for i in sim_scores]

    return df2['original_title'].iloc[movie_indices]

get_recommendations('Minions')

"""**Credits, Genres and Keywords Based Recommender**

This is a more precised Recommender
"""



features = ['cast', 'crew', 'keywords', 'genres']
for feature in features:
    df2[feature] = df2[feature].apply(literal_eval)

#list of movies by a specific director
def get_director(x):
  for i in x:
    if i['job'] == 'Director':
      return i['name']
  return np.nan

def get_list(x):
  if isinstance(x, list):
    names = [i['name'] for i in x]
    if len(names) > 3:
      names = names[:3]
    return names
  return []

df2['director'] = df2['crew'].apply(get_director)

features = ['cast', 'keywords', 'genres']
for feature in features:
    df2[feature] = df2[feature].apply(get_list)

df2[['original_title','cast', 'director', 'keywords', 'genres']].head(5)

def clean_data(x):
    if isinstance(x, list):
        return [str.lower(i.replace(" ", "")) for i in x]
    else:
        if isinstance(x, str):
            return str.lower(x.replace(" ", ""))
        else:
          return ''

features = ['cast', 'keywords', 'director', 'genres']
for feature in features:
    df2[feature] = df2[feature].apply(clean_data)

def create_soup(x):
    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])
df2['soup'] = df2.apply(create_soup, axis=1)

from sklearn.feature_extraction.text import CountVectorizer

count = CountVectorizer(stop_words='english')
count_matrix = count.fit_transform(df2['soup'])

from sklearn.metrics.pairwise import cosine_similarity

cosine_sim2 = cosine_similarity(count_matrix, count_matrix)

df2 = df2.reset_index()
indices = pd.Series(df2.index, index=df2['original_title'])

get_recommendations('Minions', cosine_sim2)


def main():
    # Define the input and output file paths
    output1 = get_recommendations('Minions', cosine_sim)
    output2 = get_recommendations('Minions', cosine_sim2)
    print('output1', output1)
    print('output2', output2)

if __name__ == '__main__':
    main()




# # common_Suggestion model
# # # -*- coding: utf-8 -*-
# # """Untitled6.ipynb

# # Automatically generated by Colab.

# # Original file is located at
# #     https://colab.research.google.com/drive/1Eotf9evllI2JM7q1aDuJDgT_2eXuup1R
# # """

# # import pandas as pd
# # import numpy as np
# # import matplotlib.pyplot as plt

# # df1=pd.read_csv('dataset/tmdb_5000_credits.csv')
# # df2=pd.read_csv('dataset/tmdb_5000_movies.csv')

# # df1.columns = ['id', 'title', 'cast', 'crew']
# # df2 = df2.merge(df1, on='id')

# # df2.head(5)

# # """**Demographic Filtering**

# # Trending Now Section (Generalised suggestions)
# # """

# # vote_mean = df2['vote_average'].mean()
# # print(vote_mean)

# # min_votes = df2['vote_count'].quantile(0.9)
# # print(min_votes)

# # filtered_movies = df2.copy().loc[df2['vote_count'] >= min_votes]
# # filtered_movies.shape

# # def weighted_rating(x, m=min_votes, C=vote_mean):
# #     v = x['vote_count']
# #     R = x['vote_average']
# #     # Calculation based on the IMDB formula
# #     return (v/(v+m) * R) + (m/(m+v) * C)

# # filtered_movies['score'] = filtered_movies.apply(weighted_rating, axis=1)

# # filtered_movies = filtered_movies.sort_values('score', ascending=False)

# # filtered_movies[['original_title', 'vote_count', 'vote_average', 'score']].head(10)

# # pop= df2.sort_values('popularity', ascending=False)

# # # plt.figure(figsize=(12,4))

# # # plt.barh(pop['original_title'].head(6),pop['popularity'].head(6), align='center',
# # #         color='skyblue')
# # # plt.gca().invert_yaxis()
# # # plt.xlabel("Popularity")
# # # plt.title("Popular Movies")



# # flask_app.py
# from flask import Flask, jsonify, request
# import pandas as pd
# import numpy as np

# app = Flask(__name__)

# # Load and prepare data once at startup
# df1 = pd.read_csv('dataset/tmdb_5000_credits.csv')
# df2 = pd.read_csv('dataset/tmdb_5000_movies.csv')
# df1.columns = ['id', 'title', 'cast', 'crew']
# df2 = df2.merge(df1, on='id')

# vote_mean = df2['vote_average'].mean()
# min_votes = df2['vote_count'].quantile(0.9)

# def weighted_rating(x, m=min_votes, C=vote_mean):
#     v = x['vote_count']
#     R = x['vote_average']
#     return (v/(v+m) * R) + (m/(m+v) * C)

# df2['score'] = df2.apply(lambda x: weighted_rating(x), axis=1)
# filtered_movies = df2[df2['vote_count'] >= min_votes].sort_values('score', ascending=False)

# @app.route("/recommendations", methods=["GET"])
# def get_recommendations():
#     limit = int(request.args.get("limit", 10))
#     top_movies = filtered_movies[['id', 'original_title', 'vote_count', 'vote_average', 'score']].head(limit)
#     result = top_movies.to_dict(orient="records")
#     return jsonify(result)

# if __name__ == "__main__":
#     app.run(debug=True, port=5001)
